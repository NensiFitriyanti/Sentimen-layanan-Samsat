{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOuXLJUwVUxjcda0twynoye"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3y5Z5M0DXj3","executionInfo":{"status":"ok","timestamp":1753105166425,"user_tz":300,"elapsed":13075,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}},"outputId":"b93460eb-298a-422d-9857-39bc1e36c4a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m204.8/253.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Error: File not found at /content/Book1.csv\n","DataFrame is empty. Please check the file path and content.\n"]}],"source":["# Langkah 1: Install dan import library\n","!pip install pandas python-docx nltk Sastrawi --quiet\n","\n","import pandas as pd\n","# from docx import Document # This library is not needed for CSV files\n","import re\n","import nltk\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","\n","nltk.download('punkt')\n","\n","# Langkah 2: Load file CSV\n","def extract_comments_from_csv(file_path):\n","    try:\n","        df = pd.read_csv(file_path, encoding='latin-1') # Added encoding\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {file_path}\")\n","        return pd.DataFrame() # Return an empty DataFrame if file not found\n","    except UnicodeDecodeError:\n","        print(f\"Error: UnicodeDecodeError with latin-1. Trying another encoding.\")\n","        try:\n","            df = pd.read_csv(file_path, encoding='ISO-8859-1') # Try another encoding\n","            return df\n","        except UnicodeDecodeError:\n","            print(f\"Error: UnicodeDecodeError with ISO-8859-1. Trying another encoding.\")\n","            try:\n","                df = pd.read_csv(file_path, encoding='cp1252') # Try another encoding\n","                return df\n","            except Exception as e:\n","                print(f\"Error reading file with cp1252 encoding: {e}\")\n","                return pd.DataFrame()\n","        except Exception as e:\n","            print(f\"Error reading file with ISO-8859-1 encoding: {e}\")\n","            return pd.DataFrame()\n","\n","\n","# Langkah 3: Jalankan fungsi ekstraksi\n","file_path = '/content/Book1.csv' # Ensure this is the correct path to your CSV file\n","df = extract_comments_from_csv(file_path)\n","\n","\n","# Langkah 4: Tampilkan sebagian data jika DataFrame is not empty\n","if not df.empty:\n","    print(df.head())\n","\n","    # Optional: Simpan sebagai CSV untuk keperluan selanjutnya\n","    df.to_csv('komentar_samsat.csv', index=False)\n","else:\n","    print(\"DataFrame is empty. Please check the file path and content.\")"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c643e61","executionInfo":{"status":"ok","timestamp":1753105166483,"user_tz":300,"elapsed":53,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}},"outputId":"0aa54b2a-1d03-4a76-ff31-7fb94fb2f544"},"source":["import nltk\n","nltk.download('vader_lexicon')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc714a6d","executionInfo":{"status":"ok","timestamp":1753105166695,"user_tz":300,"elapsed":202,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}},"outputId":"0cae4462-d178-40db-d8b2-16e63bdf5335"},"source":["import pandas as pd\n","import re\n","import nltk\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import matplotlib.pyplot as plt # Import matplotlib for plotting later\n","\n","# Re-load the original data and reapply preprocessing steps\n","\n","# Langkah 2: Load file CSV (replicated from cell O3y5Z5M0DXj3)\n","def extract_comments_from_csv(file_path):\n","    try:\n","        df = pd.read_csv(file_path, encoding='latin-1') # Added encoding\n","        print(f\"Successfully loaded data from {file_path}\") # Add success message\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {file_path}\")\n","        return pd.DataFrame() # Return an empty DataFrame if file not found\n","    except UnicodeDecodeError:\n","        print(f\"Error: UnicodeDecodeError with latin-1. Trying another encoding.\")\n","        try:\n","            df = pd.read_csv(file_path, encoding='ISO-8859-1') # Try another encoding\n","            print(f\"Successfully loaded data from {file_path} with ISO-8859-1 encoding\") # Add success message\n","            return df\n","        except UnicodeDecodeError:\n","            print(f\"Error: UnicodeDecodeError with ISO-8859-1. Trying another encoding.\")\n","            try:\n","                df = pd.read_csv(file_path, encoding='cp1252') # Try another encoding\n","                print(f\"Successfully loaded data from {file_path} with cp1252 encoding\") # Add success message\n","                return df\n","            except Exception as e:\n","                print(f\"Error reading file with cp1252 encoding: {e}\")\n","                return pd.DataFrame()\n","        except Exception as e:\n","            print(f\"Error reading file with ISO-8859-1 encoding: {e}\")\n","            return pd.DataFrame()\n","\n","# Langkah 3: Jalankan fungsi ekstraksi\n","file_path = '/content/Book1.csv' # Ensure this is the correct path to your CSV file\n","df = extract_comments_from_csv(file_path)\n","\n","\n","# Langkah 4: Lanjutkan pra-pemrosesan jika DataFrame tidak kosong\n","if not df.empty:\n","    # Rename columns based on the first row (replicated from cell eaad2c82)\n","    new_columns = df.iloc[0].tolist()\n","    df.columns = new_columns\n","    df = df.drop(0).reset_index(drop=True)\n","\n","    # Handle missing values and irrelevant rows (replicated from cells 61ef7bcd and c52fe95d)\n","    df.dropna(subset=['Isi Komentar'], inplace=True)\n","    other_cols = [col for col in df.columns if col != 'Isi Komentar']\n","    rows_to_drop = df[df[other_cols].isnull().all(axis=1)].index\n","    df.drop(rows_to_drop, inplace=True)\n","\n","    # Text cleaning (replicated from cell 4ff00012)\n","    def clean_text(text):\n","        if pd.isna(text):\n","            return \"\"\n","        text = text.lower()\n","        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","        text = re.sub(r'\\d+', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = text.strip()\n","        text = re.sub(r'\\s+', ' ', text)\n","        return text\n","\n","    df['Cleaned_Komentar'] = df['Isi Komentar'].apply(clean_text)\n","\n","    # Tokenization (replicated from cell TevlVskiF2k1)\n","    try:\n","        nltk.data.find('tokenizers/punkt')\n","    except LookupError:\n","        nltk.download('punkt')\n","\n","    def tokenize_text(text):\n","        if not text:\n","            return []\n","        return nltk.word_tokenize(text)\n","\n","    df['Tokenized_Komentar'] = df['Cleaned_Komentar'].apply(tokenize_text)\n","\n","    # Stop word removal (replicated from cell bxAhPpBrF7VZ)\n","    stop_word_factory = StopWordRemoverFactory()\n","    stop_word_remover = stop_word_remover_factory.create_stop_word_remover()\n","\n","    def remove_stopwords(tokens):\n","        if not tokens:\n","            return []\n","        text = \" \".join(tokens)\n","        filtered_text = stop_word_remover.remove(text)\n","        return filtered_text.split()\n","\n","    df['Filtered_Komentar'] = df['Tokenized_Komentar'].apply(remove_stopwords)\n","\n","    # Stemming (replicated from cell 6093c74f)\n","    stemmer_factory = StemmerFactory()\n","    stemmer = stemmer_factory.create_stemmer()\n","\n","    def stem_tokens(tokens):\n","        if not tokens:\n","            return []\n","        text = \" \".join(tokens)\n","        stemmed_text = stemmer.stem(text)\n","        return stemmed_text.split()\n","\n","    df['Stemmed_Komentar'] = df['Filtered_Komentar'].apply(stem_tokens)\n","\n","\n","    # Instantiate the VADER sentiment intensity analyzer\n","    analyzer = SentimentIntensityAnalyzer()\n","\n","    # Define a function to classify sentiment\n","    def classify_sentiment(text):\n","        if pd.isna(text) or not isinstance(text, str): # Handle potential non-string/NaN values\n","            return 'Neutral'  # Classify empty or non-string text as neutral\n","        scores = analyzer.polarity_scores(text)\n","        compound_score = scores['compound']\n","        if compound_score >= 0.05:\n","            return 'Positive'\n","        elif compound_score <= -0.05:\n","            return 'Negative'\n","        else:\n","            return 'Neutral'\n","\n","    # Apply the sentiment classification function to the 'Cleaned_Komentar' column\n","    df['Sentiment'] = df['Cleaned_Komentar'].apply(classify_sentiment)\n","\n","    # Calculate the value counts of the 'Sentiment' column\n","    sentiment_counts = df['Sentiment'].value_counts()\n","\n","    # Create a bar plot for sentiment distribution\n","    plt.figure(figsize=(8, 6))\n","    sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n","    plt.title('Sentiment Distribution of Comments')\n","    plt.xlabel('Sentiment')\n","    plt.ylabel('Number of Comments')\n","    plt.xticks(rotation=0) # Keep x-axis labels horizontal\n","    plt.tight_layout() # Adjust layout to prevent labels overlapping\n","    plt.show()\n","\n","    # Display the head of the DataFrame with the relevant columns\n","    display(df[['Cleaned_Komentar', 'Sentiment']].head())\n","\n","    # Display the counts for each sentiment category\n","    print(\"Jumlah komentar berdasarkan sentimen:\")\n","    print(sentiment_counts)\n","\n","\n","else:\n","    print(\"DataFrame is empty after loading. Cannot perform sentiment analysis.\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: File not found at /content/Book1.csv\n","DataFrame is empty after loading. Cannot perform sentiment analysis.\n"]}]},{"cell_type":"code","metadata":{"id":"ec57b9ac","executionInfo":{"status":"ok","timestamp":1753105166709,"user_tz":300,"elapsed":11,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":[],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"7f2af2a3","executionInfo":{"status":"error","timestamp":1753105166721,"user_tz":300,"elapsed":15,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}},"outputId":"1615536c-75d9-44cb-d37a-7af94372eab7"},"source":["# Select the relevant columns for the output\n","sentiment_results_df = df[['Cleaned_Komentar', 'Sentiment']]\n","\n","# Save the DataFrame to a CSV file\n","sentiment_results_df.to_csv('sentiment_results.csv', index=False)\n","\n","print(\"Hasil analisis sentimen telah disimpan ke dalam file 'sentiment_results.csv'. Anda bisa mengunduhnya dari panel file di sebelah kiri.\")"],"execution_count":5,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"None of [Index(['Cleaned_Komentar', 'Sentiment'], dtype='object')] are in the [columns]\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-5-3045901366.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select the relevant columns for the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentiment_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cleaned_Komentar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the DataFrame to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msentiment_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment_results.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Cleaned_Komentar', 'Sentiment'], dtype='object')] are in the [columns]\""]}]},{"cell_type":"code","metadata":{"id":"d71d18e4","executionInfo":{"status":"aborted","timestamp":1753105166893,"user_tz":300,"elapsed":33,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cb2f7226","executionInfo":{"status":"aborted","timestamp":1753105166898,"user_tz":300,"elapsed":17,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["# Import necessary libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re # Assuming re is needed for cleaning if not done upstream\n","import nltk # Assuming nltk is needed for tokenization if not done upstream\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory # Assuming Sastrawi is needed for stop words and stemming\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory # Assuming Sastrawi is needed for stemming\n","from nltk.tokenize import word_tokenize # Import word_tokenize explicitly\n","\n","# Re-load the original data and reapply preprocessing steps up to where df is ready\n","\n","# Langkah 2: Load file CSV (replicated from cell O3y5Z5M0DXj3)\n","def extract_comments_from_csv(file_path):\n","    try:\n","        df = pd.read_csv(file_path, encoding='latin-1') # Added encoding\n","        print(f\"Successfully loaded data from {file_path}\") # Add success message\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {file_path}\")\n","        return pd.DataFrame() # Return an empty DataFrame if file not found\n","    except UnicodeDecodeError:\n","        print(f\"Error: UnicodeDecodeError with latin-1. Trying another encoding.\")\n","        try:\n","            df = pd.read_csv(file_path, encoding='ISO-8859-1') # Try another encoding\n","            print(f\"Successfully loaded data from {file_path} with ISO-8859-1 encoding\") # Add success message\n","            return df\n","        except UnicodeDecodeError:\n","            print(f\"Error: UnicodeDecodeError with ISO-8859-1. Trying another encoding.\")\n","            try:\n","                df = pd.read_csv(file_path, encoding='cp1252') # Try another encoding\n","                print(f\"Successfully loaded data from {file_path} with cp1252 encoding\") # Add success message\n","                return df\n","            except Exception as e:\n","                print(f\"Error reading file with cp1252 encoding: {e}\")\n","                return pd.DataFrame()\n","        except Exception as e:\n","            print(f\"Error reading file with ISO-8859-1 encoding: {e}\")\n","            return pd.DataFrame()\n","\n","\n","# Langkah 3: Jalankan fungsi ekstraksi\n","file_path = '/content/Book1.csv' # Ensure this is the correct path to your CSV file\n","df = extract_comments_from_csv(file_path)\n","\n","# Langkah 4: Tampilkan sebagian data jika DataFrame is not empty\n","if not df.empty:\n","    # Rename columns based on the first row (replicated from cell eaad2c82)\n","    new_columns = df.iloc[0].tolist()\n","    df.columns = new_columns\n","    df = df.drop(0).reset_index(drop=True)\n","\n","    # Handle missing values and irrelevant rows (replicated from cells 61ef7bcd and c52fe95d)\n","    df.dropna(subset=['Isi Komentar'], inplace=True)\n","    other_cols = [col for col in df.columns if col != 'Isi Komentar']\n","    rows_to_drop = df[df[other_cols].isnull().all(axis=1)].index\n","    df.drop(rows_to_drop, inplace=True)\n","\n","    # Text cleaning (replicated from cell 4ff00012)\n","    def clean_text(text):\n","        if pd.isna(text):\n","            return \"\"\n","        text = text.lower()\n","        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","        text = re.sub(r'\\d+', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = text.strip()\n","        text = re.sub(r'\\s+', ' ', text)\n","        return text\n","\n","    df['Cleaned_Komentar'] = df['Isi Komentar'].apply(clean_text)\n","\n","    # Tokenization (replicated from cell TevlVskiF2k1)\n","    # Ensure punkt is downloaded if needed for word_tokenize in this environment\n","    try:\n","        nltk.data.find('tokenizers/punkt')\n","    except LookupError:\n","        nltk.download('punkt')\n","\n","    def tokenize_text(text):\n","        if not text:\n","            return []\n","        return word_tokenize(text)\n","\n","    df['Tokenized_Komentar'] = df['Cleaned_Komentar'].apply(tokenize_text)\n","\n","    # Stop word removal (replicated from cell bxAhPpBrF7VZ)\n","    stop_word_factory = StopWordRemoverFactory()\n","    stop_word_remover = stop_word_factory.create_stop_word_remover()\n","\n","    def remove_stopwords(tokens):\n","        if not tokens:\n","            return []\n","        text = \" \".join(tokens)\n","        filtered_text = stop_word_remover.remove(text)\n","        return filtered_text.split()\n","\n","    df['Filtered_Komentar'] = df['Tokenized_Komentar'].apply(remove_stopwords)\n","\n","    # Stemming (replicated from cell 6093c74f)\n","    stemmer_factory = StemmerFactory()\n","    stemmer = stemmer_factory.create_stemmer()\n","\n","    def stem_tokens(tokens):\n","        if not tokens:\n","            return []\n","        text = \" \".join(tokens)\n","        stemmed_text = stemmer.stem(text)\n","        return stemmed_text.split()\n","\n","    df['Stemmed_Komentar'] = df['Filtered_Komentar'].apply(stem_tokens)\n","\n","\n","    # Calculate the value counts of the 'Platfrom' column\n","    if 'Platfrom' in df.columns:\n","        platform_counts = df['Platfrom'].value_counts()\n","\n","        # Create a bar plot for platform distribution\n","        plt.figure(figsize=(10, 6))\n","        platform_counts.plot(kind='bar', color='skyblue')\n","        plt.title('Distribution of Platforms')\n","        plt.xlabel('Platform')\n","        plt.ylabel('Number of Comments')\n","        plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n","        plt.tight_layout() # Adjust layout\n","        plt.show()\n","    else:\n","        print(\"Column 'Platfrom' not found in the DataFrame.\")\n","\n","else:\n","    print(\"DataFrame is empty. Cannot plot platform distribution.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"393ba267","executionInfo":{"status":"aborted","timestamp":1753105166906,"user_tz":300,"elapsed":24,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["import matplotlib.pyplot as plt\n","\n","# Calculate the value counts of the 'Platfrom' column\n","if not df.empty and 'Platfrom' in df.columns:\n","    platform_counts = df['Platfrom'].value_counts()\n","\n","    # Create a bar plot for platform distribution\n","    plt.figure(figsize=(10, 6))\n","    platform_counts.plot(kind='bar', color='skyblue')\n","    plt.title('Distribution of Platforms')\n","    plt.xlabel('Platform')\n","    plt.ylabel('Number of Comments')\n","    plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n","    plt.tight_layout() # Adjust layout\n","    plt.show()\n","else:\n","    print(\"DataFrame is empty or 'Platfrom' column is missing. Cannot plot platform distribution.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgTL5K22nGMP","executionInfo":{"status":"aborted","timestamp":1753105166909,"user_tz":300,"elapsed":26,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["import nltk\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import re # Import re for text cleaning\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory # Import Sastrawi for stop word removal\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory # Import Sastrawi for stemming\n","\n","# Download the VADER lexicon\n","nltk.download('vader_lexicon')\n","# Download punkt for tokenization if not already downloaded\n","try:\n","    nltk.data.find('tokenizers/punkt')\n","except LookupError:\n","    nltk.download('punkt')\n","\n","\n","# Langkah 2: Load file CSV (replicated from cell O3y5Z5M0DXj3)\n","def extract_comments_from_csv(file_path):\n","    try:\n","        df = pd.read_csv(file_path, encoding='latin-1') # Added encoding\n","        print(f\"Successfully loaded data from {file_path}\") # Add success message\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {file_path}\")\n","        return pd.DataFrame() # Return an empty DataFrame if file not found\n","    except UnicodeDecodeError:\n","        print(f\"Error: UnicodeDecodeError with latin-1. Trying another encoding.\")\n","        try:\n","            df = pd.read_csv(file_path, encoding='ISO-8859-1') # Try another encoding\n","            print(f\"Successfully loaded data from {file_path} with ISO-8859-1 encoding\") # Add success message\n","            return df\n","        except UnicodeDecodeError:\n","            print(f\"Error: UnicodeDecodeError with ISO-8859-1. Trying another encoding.\")\n","            try:\n","                df = pd.read_csv(file_path, encoding='cp1252') # Try another encoding\n","                print(f\"Successfully loaded data from {file_path} with cp1252 encoding\") # Add success message\n","                return df\n","            except Exception as e:\n","                print(f\"Error reading file with cp1252 encoding: {e}\")\n","                return pd.DataFrame()\n","        except Exception as e:\n","            print(f\"Error reading file with ISO-8859-1 encoding: {e}\")\n","            return pd.DataFrame()\n","\n","# Langkah 3: Jalankan fungsi ekstraksi\n","file_path = '/content/Book1.csv' # Ensure this is the correct path to your CSV file\n","df = extract_comments_from_csv(file_path)\n","\n","# Langkah 4: Lanjutkan pra-pemrosesan jika DataFrame tidak kosong\n","if not df.empty:\n","    # Rename columns based on the first row (replicated from cell eaad2c82)\n","    new_columns = df.iloc[0].tolist()\n","    df.columns = new_columns\n","    df = df.drop(0).reset_index(drop=True)\n","\n","    # Handle missing values and irrelevant rows (replicated from cells 61ef7bcd and c52fe95d)\n","    df.dropna(subset=['Isi Komentar'], inplace=True)\n","    other_cols = [col for col in df.columns if col != 'Isi Komentar']\n","    rows_to_drop = df[df[other_cols].isnull().all(axis=1)].index\n","    df.drop(rows_to_drop, inplace=True)\n","\n","    # Text cleaning (replicated from cell 4ff00012)\n","    def clean_text(text):\n","        if pd.isna(text):\n","            return \"\"\n","        text = text.lower()\n","        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","        text = re.sub(r'\\d+', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = text.strip()\n","        text = re.sub(r'\\s+', ' ', text)\n","        return text\n","\n","    df['Cleaned_Komentar'] = df['Isi Komentar'].apply(clean_text)\n","\n","    # Tokenization (replicated from cell TevlVskiF2k1)\n","    def tokenize_text(text):\n","        if not text:\n","            return []\n","        return nltk.word_tokenize(text)\n","\n","    df['Tokenized_Komentar'] = df['Cleaned_Komentar'].apply(tokenize_text)\n","\n","    # Stop word removal (replicated from cell bxAhPpBrF7VZ)\n","    stop_word_factory = StopWordRemoverFactory()\n","    stop_word_remover = stop_word_factory.create_stop_word_remover()\n","\n","    def remove_stopwords(tokens):\n","        if not tokens:\n","            return []\n","        text = \" \".join(tokens)\n","        filtered_text = stop_word_remover.remove(text)\n","        return filtered_text.split()\n","\n","    df['Filtered_Komentar'] = df['Tokenized_Komentar'].apply(remove_stopwords)\n","\n","    # Stemming (replicated from cell 6093c74f)\n","    stemmer_factory = StemmerFactory()\n","    stemmer = stemmer_factory.create_stemmer()\n","\n","    def stem_tokens(tokens):\n","        if not tokens:\n","            return []\n","        text = \" \".join(tokens)\n","        stemmed_text = stemmer.stem(text)\n","        return stemmed_text.split()\n","\n","    df['Stemmed_Komentar'] = df['Filtered_Komentar'].apply(stem_tokens)\n","\n","    # Instantiate the VADER sentiment intensity analyzer\n","    analyzer = SentimentIntensityAnalyzer()\n","\n","    # Define a function to classify sentiment\n","    def classify_sentiment(text):\n","        if pd.isna(text) or not isinstance(text, str):\n","            return 'Neutral'  # Classify empty or non-string text as neutral\n","        scores = analyzer.polarity_scores(text)\n","        compound_score = scores['compound']\n","        if compound_score >= 0.05:\n","            return 'Positive'\n","        elif compound_score <= -0.05:\n","            return 'Negative'\n","        else:\n","            return 'Neutral'\n","\n","    # Apply the sentiment classification function to the 'Cleaned_Komentar' column\n","    df['Sentiment'] = df['Cleaned_Komentar'].apply(classify_sentiment)\n","\n","    # 1 & 2: Calculate and plot Sentiment Distribution\n","    sentiment_counts = df['Sentiment'].value_counts()\n","    plt.figure(figsize=(8, 6))\n","    sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n","    plt.title('Sentiment Distribution of Comments')\n","    plt.xlabel('Sentiment')\n","    plt.ylabel('Number of Comments')\n","    plt.xticks(rotation=0)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # 3 & 4: Calculate and plot Platform Distribution\n","    if 'Platfrom' in df.columns:\n","        platform_counts = df['Platfrom'].value_counts()\n","        plt.figure(figsize=(10, 6))\n","        platform_counts.plot(kind='bar', color='skyblue')\n","        plt.title('Distribution of Platforms')\n","        plt.xlabel('Platform')\n","        plt.ylabel('Number of Comments')\n","        plt.xticks(rotation=45, ha='right')\n","        plt.tight_layout()\n","        plt.show()\n","    else:\n","        print(\"Column 'Platfrom' not found in the DataFrame. Cannot plot platform distribution.\")\n","\n","\n","    # 5, 6 & 7: Flatten stemmed words and find most common words\n","    all_stemmed_words = [word for tokens in df['Stemmed_Komentar'] for word in tokens]\n","    fdist = nltk.FreqDist(all_stemmed_words)\n","    most_common_words = fdist.most_common(20)\n","\n","    # Print the most common words\n","    print(\"Most common words:\")\n","    print(most_common_words)\n","\n","    # 8: Print numerical summary of sentiment counts\n","    print(\"\\nJumlah komentar berdasarkan sentimen:\")\n","    print(sentiment_counts)\n","\n","else:\n","    print(\"DataFrame is empty after loading. Cannot perform analysis.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49752d04","executionInfo":{"status":"aborted","timestamp":1753105166911,"user_tz":300,"elapsed":20,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["# Sentiment Analysis Dashboard\n","\n","## Sentiment Distribution\n","\n","# Display the sentiment distribution plot\n","# The code to generate this plot was in a previous cell:\n","# import matplotlib.pyplot as plt\n","# sentiment_counts = df['Sentiment'].value_counts()\n","# plt.figure(figsize=(8, 6))\n","# sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n","# plt.title('Sentiment Distribution of Comments')\n","# plt.xlabel('Sentiment')\n","# plt.ylabel('Number of Comments')\n","# plt.xticks(rotation=0)\n","# plt.tight_layout()\n","# plt.show()\n","\n","# Display the numerical sentiment counts\n","print(\"Jumlah komentar berdasarkan sentimen:\")\n","if not df.empty and 'Sentiment' in df.columns:\n","    print(df['Sentiment'].value_counts())\n","else:\n","    print(\"DataFrame is empty or 'Sentiment' column is missing. Cannot display sentiment counts.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"704cfda1"},"source":["**Reasoning**:\n","Add a Markdown heading for the platform distribution and include the code to generate the plot.\n","\n"]},{"cell_type":"code","metadata":{"id":"a9a0a9a1","executionInfo":{"status":"aborted","timestamp":1753105166913,"user_tz":300,"elapsed":17,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["## Platform Distribution\n","\n","# Display the platform distribution plot\n","# The code to generate this plot was in a previous cell:\n","# import matplotlib.pyplot as plt\n","# platform_counts = df['Platfrom'].value_counts()\n","# plt.figure(figsize=(10, 6))\n","# platform_counts.plot(kind='bar', color='skyblue')\n","# plt.title('Distribution of Platforms')\n","# plt.xlabel('Platform')\n","# plt.ylabel('Number of Comments')\n","# plt.xticks(rotation=45, ha='right')\n","# plt.tight_layout()\n","# plt.show()\n","\n","# Display the numerical platform counts\n","print(\"Jumlah komentar berdasarkan Platform:\")\n","if not df.empty and 'Platfrom' in df.columns:\n","    print(df['Platfrom'].value_counts())\n","else:\n","    print(\"DataFrame is empty or 'Platfrom' column is missing. Cannot display platform counts.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7a89ab6f"},"source":["**Reasoning**:\n","Add a Markdown heading for the most common topics and include the code to print the most common words.\n","\n"]},{"cell_type":"code","metadata":{"id":"21b5b68e","executionInfo":{"status":"aborted","timestamp":1753105166915,"user_tz":300,"elapsed":18,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d609ec19","executionInfo":{"status":"aborted","timestamp":1753105166925,"user_tz":300,"elapsed":16,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["import matplotlib.pyplot as plt\n","\n","# Sentiment Distribution Plot\n","plt.figure(figsize=(9, 7)) # Increased figure size\n","sentiment_counts.plot(kind='bar', color=['#4CAF50', '#F44336', '#2196F3']) # Changed colors\n","plt.title('Distribusi Sentimen Komentar', fontsize=14) # Added Indonesian title, increased font size\n","plt.xlabel('Sentimen', fontsize=12) # Added Indonesian label, increased font size\n","plt.ylabel('Jumlah Komentar', fontsize=12) # Added Indonesian label, increased font size\n","plt.xticks(rotation=0) # Keep x-axis labels horizontal\n","plt.yticks(fontsize=10) # Increased y-tick font size\n","plt.grid(axis='y', linestyle='--', alpha=0.7) # Added a light grid for readability\n","plt.tight_layout()\n","plt.show()\n","\n","# Platform Distribution Plot\n","plt.figure(figsize=(11, 7)) # Increased figure size\n","platform_counts.plot(kind='bar', color='#FFC107') # Changed color to yellow\n","plt.title('Distribusi Komentar Berdasarkan Platform', fontsize=14) # Added Indonesian title, increased font size\n","plt.xlabel('Platform', fontsize=12) # Added Indonesian label, increased font size\n","plt.ylabel('Jumlah Komentar', fontsize=12) # Added Indonesian label, increased font size\n","plt.xticks(rotation=45, ha='right', fontsize=10) # Rotate labels, align right, increased font size\n","plt.yticks(fontsize=10) # Increased y-tick font size\n","plt.grid(axis='y', linestyle='--', alpha=0.7) # Added a light grid for readability\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"069873c3","executionInfo":{"status":"aborted","timestamp":1753105166928,"user_tz":300,"elapsed":13770,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["# Re-run the necessary steps to load and preprocess the data, including tokenization\n","\n","import pandas as pd\n","import re\n","import nltk\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory # Keep this import as it might be needed later\n","\n","# Langkah 2: Load file CSV (replicated from cell O3y5Z5M0DXj3)\n","def extract_comments_from_csv(file_path):\n","    try:\n","        df = pd.read_csv(file_path, encoding='latin-1') # Added encoding\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {file_path}\")\n","        return pd.DataFrame() # Return an empty DataFrame if file not found\n","    except UnicodeDecodeError:\n","        print(f\"Error: UnicodeDecodeError with latin-1. Trying another encoding.\")\n","        try:\n","            df = pd.read_csv(file_path, encoding='ISO-8859-1') # Try another encoding\n","            return df\n","        except UnicodeDecodeError:\n","            print(f\"Error: UnicodeDecodeError with ISO-8859-1. Trying another encoding.\")\n","            try:\n","                df = pd.read_csv(file_path, encoding='cp1252') # Try another encoding\n","                return df\n","            except Exception as e:\n","                print(f\"Error reading file with cp1252 encoding: {e}\")\n","                return pd.DataFrame()\n","        except Exception as e:\n","            print(f\"Error reading file with ISO-8859-1 encoding: {e}\")\n","            return pd.DataFrame()\n","\n","# Langkah 3: Jalankan fungsi ekstraksi\n","file_path = '/content/Book1.csv' # Ensure this is the correct path to your CSV file\n","df = extract_comments_from_csv(file_path)\n","\n","# Langkah 4: Lanjutkan pra-pemrosesan jika DataFrame tidak kosong\n","if not df.empty:\n","    # Rename columns based on the first row (replicated from cell eaad2c82)\n","    new_columns = df.iloc[0].tolist()\n","    df.columns = new_columns\n","    df = df.drop(0).reset_index(drop=True)\n","\n","    # Handle missing values and irrelevant rows (replicated from cells 61ef7bcd and c52fe95d)\n","    df.dropna(subset=['Isi Komentar'], inplace=True)\n","    other_cols = [col for col in df.columns if col != 'Isi Komentar']\n","    rows_to_drop = df[df[other_cols].isnull().all(axis=1)].index\n","    df.drop(rows_to_drop, inplace=True)\n","\n","    # Text cleaning (replicated from cell 4ff00012)\n","    def clean_text(text):\n","        if pd.isna(text):\n","            return \"\"\n","        text = text.lower()\n","        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","        text = re.sub(r'\\d+', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = text.strip()\n","        text = re.sub(r'\\s+', ' ', text)\n","        return text\n","\n","    df['Cleaned_Komentar'] = df['Isi Komentar'].apply(clean_text)\n","\n","    # Tokenization (replicated from cell TevlVskiF2k1)\n","    try:\n","        nltk.data.find('tokenizers/punkt')\n","    except LookupError:\n","        nltk.download('punkt')\n","\n","    def tokenize_text(text):\n","        if not text:\n","            return []\n","        return nltk.word_tokenize(text)\n","\n","    df['Tokenized_Komentar'] = df['Cleaned_Komentar'].apply(tokenize_text)\n","\n","    # Display the original and tokenized comments\n","    display(df[['Isi Komentar', 'Tokenized_Komentar']].head())\n","\n","else:\n","    print(\"DataFrame is empty after loading. Cannot display tokenized comments.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2585084a","executionInfo":{"status":"aborted","timestamp":1753105166931,"user_tz":300,"elapsed":13770,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"source":["# Execute the code in cell cb2f7226 to display the platform distribution plot\n","# This cell contains the code to load data, preprocess, and plot platform distribution.\n","# I will replicate the plotting part here for clarity and execution order.\n","\n","import matplotlib.pyplot as plt\n","\n","# Calculate the value counts of the 'Platfrom' column\n","if not df.empty and 'Platfrom' in df.columns:\n","    platform_counts = df['Platfrom'].value_counts()\n","\n","    # Create a bar plot for platform distribution\n","    plt.figure(figsize=(10, 6))\n","    platform_counts.plot(kind='bar', color='skyblue')\n","    plt.title('Distribution of Platforms')\n","    plt.xlabel('Platform')\n","    plt.ylabel('Number of Comments')\n","    plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n","    plt.tight_layout() # Adjust layout\n","    plt.show()\n","else:\n","    print(\"DataFrame is empty or 'Platfrom' column is missing. Cannot plot platform distribution.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","sns.countplot(data=df, x='Sentiment', palette='viridis')\n","plt.title('Distribusi Sentimen Komentar')\n","plt.xlabel('Kategori Sentimen')\n","plt.ylabel('Jumlah Komentar')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"JkzkUNEDNWBS","executionInfo":{"status":"aborted","timestamp":1753105166933,"user_tz":300,"elapsed":13769,"user":{"displayName":"Fitriyashop","userId":"06162914796851461187"}}},"execution_count":null,"outputs":[]}]}